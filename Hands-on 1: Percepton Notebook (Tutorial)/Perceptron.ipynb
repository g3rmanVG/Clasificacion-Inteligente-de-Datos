{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e0d9f2",
   "metadata": {},
   "source": [
    "<h2>Hands-on 1: Percepton Notebook (Tutorial)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d21775",
   "metadata": {},
   "source": [
    "<h3>1. Fundamentos de la técnica.</h3>\n",
    "\n",
    "El Perceptron es una de las arquitecturas de redes neuronales artificiales más simples, introducida por Frank Rosenblatt en 1957. Se utiliza principalmente para la clasificación binaria y se basa en una neurona artificial única que imita el comportamiento básico de una neurona biológica.\n",
    "\n",
    "Sus elementos básicos son: Características de Entrada ($X$), Pesos ($W$), una Función de Suma (para calcular la suma ponderada), una Función de Activación (generalmente la función escalón de Heaviside), un Sesgo (Bias, $b$) y un Algoritmo de Aprendizaje.\n",
    "\n",
    "Mecanismo: El Perceptrón toma múltiples entradas, realiza una suma ponderada de estas, y aplica una función de activación (función escalón) para producir una salida binaria (clase 0 o 1). La clave del Perceptrón es su regla de aprendizaje, que ajusta los pesos del modelo iterativamente con el objetivo de clasificar correctamente los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d2883",
   "metadata": {},
   "source": [
    "<h3>2. Modelo matemático del perceptrón.</h3>\n",
    "\n",
    "    2.1 Función de Suma Ponderada:\n",
    "\n",
    "El Perceptrón primero calcula la suma ponderada de las entradas, donde cada entrada ($x_i$) se multiplica por su peso correspondiente ($w_i$).\n",
    "\n",
    "$$z = w_1x_1 + w_2x_2 + \\ldots + w_nx_n = \\mathbf{X}^\\mathbf{T}\\mathbf{W}$$\n",
    "\n",
    "$\\mathbf{X}$: Vector de entradas.\n",
    "\n",
    "$\\mathbf{W}$: Vector de pesos.\n",
    "\n",
    "    2.2 Función de Activación y Salida:\n",
    "\n",
    "El resultado de la suma ponderada se pasa a través de una función de activación para determinar la salida binaria. La inclusión del sesgo ($b$) se representa en la ecuación final de la salida:\n",
    "\n",
    "$$\\text{Salida} = f_{W,b}(\\mathbf{X})=h(\\mathbf{X}\\mathbf{W} + b)$$\n",
    "\n",
    "Donde $h(z)$ es la función escalón, definida como:\n",
    "\n",
    "$$h(z) = \\begin{cases} 0 & \\text{si } z <br \\text{Umbral} \\\\ 1 & \\text{si } z \\geq \\text{Umbral} \\end{cases}$$\n",
    "\n",
    "    2.3 Regla de Aprendizaje (Actualización de Pesos):\n",
    "\n",
    "Durante el entrenamiento, los pesos se ajustan para minimizar el error entre la salida predicha ($\\hat{y}_j$) y el valor real ($y_j$). La fórmula de actualización de pesos es:\n",
    "\n",
    "$$\\mathbf{w}_{i,j} = \\mathbf{w}_{i,j} + \\eta (y_j - \\hat{y}_j)x_i$$\n",
    "\n",
    "Donde:$\\mathbf{w}_{i,j}$: Peso entre la $i$-ésima entrada y la $j$-ésima neurona de salida.\n",
    "\n",
    "$(y_j - \\hat{y}_j)$: Error de predicción.\n",
    "\n",
    "$\\eta$: Tasa de aprendizaje (controla la magnitud del ajuste).\n",
    "\n",
    "$x_i$: Valor de la $i$-ésima entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6b506",
   "metadata": {},
   "source": [
    "<h3>3. Descripción de las librerías.</h3>\n",
    "\n",
    "Para la implementación del Perceptrón en Python se realizará con la ayuda de la librería Scikit-learn:\n",
    "\n",
    "    Clase Perceptron: (del módulo sklearn.linear_model) \n",
    "\n",
    "Contiene la implementación del algoritmo Perceptrón.\n",
    "\n",
    "    Función accuracy_score: (del módulo sklearn.metrics) \n",
    "\n",
    "Es la métrica empleada para calcular la Precisión (Accuracy) del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0bd5f",
   "metadata": {},
   "source": [
    "<h3>4. Pipeline.</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5752f7d",
   "metadata": {},
   "source": [
    "    4.1 Feature Engineering\n",
    "\n",
    "Después de revisar la teoría, implementaremos una compuerta lógica AND con ayuda del Perceptrón.\n",
    "\n",
    "Entradas ($\\mathbf{X}$):\n",
    "\n",
    "En este caso, hay dos entradas ($x_1, x_2$)  con dos posibles valores (0 o 1). Estas serán nuestras características.\n",
    "\n",
    "Salida ($\\mathbf{y}$):\n",
    "\n",
    "Tenemos una única salida ($y$), que es el resultado de la operación AND ($x_1 \\text{ AND } x_2$). Esta será la clase objetivo.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa04b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entradas X (patrones): \n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "\n",
      "Salidas Y (etiquetas):\n",
      " [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "y_train = np.array([0, 0, 0, 1])\n",
    "\n",
    "print(f\"Entradas X (patrones): \\n{X_train}\")\n",
    "print(f\"\\nSalidas Y (etiquetas):\\n {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412f44a",
   "metadata": {},
   "source": [
    "    4.2 Model Selection\n",
    "\n",
    "Se emplea un Percetrón porque la compuerta lógica AND es un problema de clasificación linealmente separable. Es decir, es posible dibujar una linea recta que separe perfectamente las entradas que resultan en la clase 0 de la que da resultado 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237d00b",
   "metadata": {},
   "source": [
    "    4.3 Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af284d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Modelo ---\n",
      "Pesos finales (w): [0.2 0.2]\n",
      "Bias final (b): -0.20000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el Perceptrón\n",
    "model = Perceptron(max_iter=100, tol=None, random_state=42, eta0=0.1)\n",
    "\n",
    "# Entrenar el Perceptrón\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- Modelo ---\")\n",
    "print(f\"Pesos finales (w): {model.coef_[0]}\")\n",
    "print(f\"Bias final (b): {model.intercept_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1ebf0",
   "metadata": {},
   "source": [
    "    4.4 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac3a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicciones ---\n",
      "Entrada: [0 0] | Salida esperada: 0 | Salida Predicha: 0\n",
      "Entrada: [0 1] | Salida esperada: 0 | Salida Predicha: 0\n",
      "Entrada: [1 0] | Salida esperada: 0 | Salida Predicha: 0\n",
      "Entrada: [1 1] | Salida esperada: 1 | Salida Predicha: 1\n"
     ]
    }
   ],
   "source": [
    "def test_and_gate(model, X_data, y_true):\n",
    "    print(\"\\n--- Predicciones ---\")\n",
    "    \n",
    "    for x, y_expected in zip(X_data, y_true):\n",
    "        x_input = x.reshape(1, -1)\n",
    "        y_pred = model.predict(x_input)[0]\n",
    "        \n",
    "        print(f\"Entrada: {x} | Salida esperada: {y_expected} | Salida Predicha: {y_pred}\")\n",
    "\n",
    "\n",
    "test_and_gate(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146e8c0",
   "metadata": {},
   "source": [
    "    4.5 Model Evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a54796f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación del Modelo ---\n",
      "Precisión (Accuracy): 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "print(\"\\n--- Evaluación del Modelo ---\")\n",
    "print(f\"Precisión (Accuracy): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad6664",
   "metadata": {},
   "source": [
    "Despues de calcular los resultados, podemos decir que el Perceptrón logró clasificar corectamente el 100% de los casos de la compuerta AND, lo cual confirma que el algoritmo funciona y es capaz de aplicarse a este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9b411",
   "metadata": {},
   "source": [
    "<h3>5. Referecias bibliográficas</h3>\n",
    "\n",
    "GeeksforGeeks. (s.f.). Perceptron class in Sklearn. https://www.geeksforgeeks.org/machine-learning/sklearn-perceptron/\n",
    "\n",
    "GeeksforGeeks. What is Perceptron | The Simplest Artificial neural network. https://www.geeksforgeeks.org/machine-learning/what-is-perceptron-the-simplest-artificial-neural-network/\n",
    "\n",
    "Scikit-learn. (s.f.). Perceptron — scikit-learn 1.7.2 documentation. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
